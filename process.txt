用神经网络个体+遗传算法实现玩Pacman的AI的过程
    1、完整的创建游戏，使用网格严格规定玩家和幽灵的转向时间

    2、构建拥有双隐藏层的Pacman个体，在神经网络中的三层中，我们有
        输入层：负责参数的传入，接受游戏信息
        隐藏层：用来让AI自己计算，自己做决策
        输出层：根据AI隐藏层自己的计算，输出下一步移动的方向

        对于16组数据的选择，我们首先在training_game里面添加了新的函数来获取相关数据，
        然后我们需要对数据做归一化，归一化是为了收敛数据，增加数值稳定性

        （要做的！写获取数据的方程，选择归一化的方式）结束啦
        数据的获取是在training_AIs里面，我们通过获取场上的各种数据来得到input_vector，这些就是输入给
        一个个神经网络AI的数据

        数据的归一化目前很简单，就是在获取数据的时候直接除以一个整数

    3.18现在已经可以自动生成一个神经网络构成的AI了，这个双隐藏层的AI会自己计算权重，判断每一帧的时候该去什么方向
    要做的！
    3、要准备开始生成种群了，也就是初始化一堆个体。第一步呢是评价每个个体的适应度
    我先写了生成第一个种群:productTheFirstGeneration来产生第一波个体们
    然后就是运行generation:输入是不管多少个个体们，用list，输出是每个个体的大脑结构和分数和存活时间

    我现在想根据遗传算法，因为我有40个个体，我发现我每次运行第一次，都有6-7个是在第一代算不错的婴儿，
    所以我就想在遗传算法的每一步中完整的保留前12.5%的个体进入下一代（这里取整个数就行）。

    然后我会在第二部分个体选择crossover前50%的个体，相当于父母的两个列表随便交换，一一对应，
    等价于两个列表的第n个数有50%的概率产生交换。如果算第一代的话，这时候就是20个个体进行交换产生10个后代，
    所以我再重新交换第二次再产生10个后代。这时候一共有25个个体了。然后我会在这25个个体中任选15个，
    每个个体的每个数，有5%的几率变异，再把这15个个体添加到下一个子代里。所以这样下一代就有了新的40个个体

    上面那个遗传给后代的方式是不合理的，过度的基因重组反而会降低个体的能力

    所以我决定孩子70%的权重来自一方，30%来自另一方，在这样的一个改动下，生存时间最长是1669，10代之后的最大分数是170分
    word2025.3.19

    让我来试试增加一倍的初代个体（80），这样的话我发现有一个个体可以活到上限了，即使它不怎么吃豆

    注：目前计算适应度的唯一指标是个体的得分

    我现在再来增加一倍个体，在基因的多样性给他拉满（160） 到现在为止一直是每个点5%的变异率，有的高了，基因突变在自然界没有那么高
    所以会导致个体有时候的表现变差

    出现了种群趋同，前12.5%的个体取代了所有个体，所以提高变异率，父母交换0.5到0.9随机交换，变异率变为3%

    3.24：前50%截断容易导致多样性不足，所以尝试改成轮盘赌

    3.30 推测遗传uniforme可能并不会在神经元结构下取得良好的表现，所以我尝试了single point crossover，
    然后我在第一次采用种群数量50，代数10代的时候，有了惊人的优化。230 -350 -420 -360 -320 -340 -380 -330

    好吧让我失望了，推测是平等的变异规则导致丢失了优良个体

    我在做一个可视化AI，超级经典的坑：AI每一帧都做决策，帧率降低了行为就会变烂，所以尝试加入帧率归一化

    很好，归一化取得了很大的成功，我采用的策略是添加一个新的输入，计算这一帧到上一帧的时间，我会normalize帧率
    让current fps = 1/每一帧率的duration。这样得到了实时帧率之后，我们就可以归一化这个帧率/100作为一个变量输入。

    这样的效果很好，我只用50种群数量和5代，我的训练结果和展示结果就变的差不多了，也就是说AI 适应了这个输入！

Utilisation d'individus du réseau neuronal + algorithme génétique pour réaliser le processus de lecture de Pacman AI
 1. Créez entièrement le jeu, en utilisant des grilles pour réguler strictement le temps de rotation des joueurs et des fantômes

 2. Construisez un individu Pacman avec des doubles couches cachées. Parmi les trois couches du réseau neuronal, nous avons.
 Couche d'entrée : responsable de la transmission des paramètres et de l'acceptation des informations sur le jeu
 Couche cachée : utilisée pour permettre à l'IA de calculer et de prendre des décisions par elle-même
 Couche de sortie : sur la base des propres calculs de la couche cachée de l'IA, affichez la direction du prochain mouvement.

 Pour la sélection de 16 ensembles de données, nous avons d'abord ajouté une nouvelle fonction dans training_game pour obtenir des données pertinentes.
 Ensuite, nous devons normaliser les données. La normalisation consiste à faire converger les données et à augmenter la stabilité numérique.

 (À faire ! Écrivez l'équation pour obtenir les données et choisissez la méthode de normalisation)
 Les données sont obtenues dans training_AIs. Nous obtenons le input_vector en obtenant diverses données sur le terrain. Ce sont les entrées à.
 Données de l'IA du réseau neuronal une par une

 La normalisation des données est actuellement très simple, elle consiste à diviser directement par un nombre entier lors de l'obtention des données.

3.18 Il est désormais possible de générer automatiquement une IA composée d'un réseau de neurones. Cette IA à double couche cachée calculera ses propres poids et déterminera la direction à suivre dans chaque image.
 Je dois le faire !
 3. Préparez-vous à commencer à générer la population, c'est-à-dire initialisez un groupe d'individus. La première étape consiste à évaluer la forme physique de chaque individu
 J'ai d'abord écrit pour générer le premier groupe : productTheFirstGeneration pour générer la première vague d'individus.
 Ensuite, il est exécuté et généré : l'entrée correspond au nombre d'individus que nous utilisons, utilisez une liste, et le résultat est la structure cérébrale, le score et le temps de partition de chaque personne.

 Je veux maintenant utiliser l'algorithme génétique, car j'ai 40 individus, et j'ai découvert qu'à chaque fois que je cours pour la première fois, il y a 6 à 7 bébés qui sont considérés comme bons dans la première génération, donc je veux conserver complètement les 12,5 % précédents à chaque étape de l'algorithme génétique.

 Ensuite je sélectionnerai les 50% des individus les plus performants dans la deuxième partie du crossover, ce qui équivaut à deux listes de parents facilement échangées, une correspondance individuelle,
 Cela équivaut à une probabilité de 50 % que le nième numéro des deux listes soit échangé. Si un individu se reproduit et produit 10 petits,
 Je rééchange donc une seconde fois et produis 10 descendants supplémentaires. Il y a actuellement 25 individus au total. Ensuite, je sélectionnerai au hasard 15 de ces 25 individus,
 Chaque donnée de chaque individu présente une variation de 5 %, puis ces 15 individus sont ajoutés à la progéniture suivante. La prochaine génération compte donc 40 nouveaux individus

 La méthode ci-dessus de transmission à la progéniture est déraisonnable. Une recombinaison génétique excessive réduira les capacités de l'individu.

 J'ai donc décidé que 70 % du poids de l'enfant venait d'un côté et 30 % de l'autre côté. Avec un tel changement, la durée de survie la plus longue est de 1669 et le score maximum après 10 générations est de 170 points.
 mot2025.3.19

 Permettez-moi d'essayer de doubler le nombre d'individus de première génération (80). Dans ce cas, j'ai découvert qu'un individu peut vivre jusqu'à la limite supérieure, même s'il ne mange pas beaucoup de haricots.

 Remarque : Le seul indicateur actuellement utilisé pour calculer la condition physique est le score individuel.

 Maintenant, je vais doubler le nombre d'individus et les remplir de diversité génétique (160). Jusqu'à présent, le taux de mutation à chaque point a été de 5 %. Certaines mutations génétiques ne sont pas si élevées dans la nature.
 Par conséquent, cela entraînera parfois une détérioration des performances de l’individu.

 Une convergence de population se produit et les 12,5 % des individus les plus riches remplacent tous les individus, de sorte que le taux de mutation est augmenté au hasard de 0,5 à 0,9 et le taux de mutation devient 3 %.
 3.24 : La première troncature de 50 % peut facilement conduire à une diversité insuffisante, alors essayez de la changer en roulette

 3.30 J'ai émis l'hypothèse que l'uniformité génétique pourrait ne pas fonctionner correctement dans la structure des neurones, j'ai donc essayé le croisement en un seul point,
Puis, lorsque j’ai adopté pour la première fois la taille de la population de 50 et le nombre de générations de 10, j’ai réalisé une optimisation étonnante. 230 -350 -420 -360 -320 -340 -380 -330

D'accord, je suis déçu. Je suppose que ce sont les règles de mutation égale qui conduisent à la perte d’excellents individus.

Je travaille sur une IA visuelle. Un écueil super classique : l’IA prend des décisions à chaque image. Si la fréquence d'images est réduite, le comportement deviendra mauvais, essayez donc d'ajouter une normalisation de la fréquence d'images.

Eh bien, la normalisation a été un grand succès, la stratégie que j'ai adoptée était d'ajouter une nouvelle entrée, de calculer le temps entre cette image et l'image précédente, et je normaliserais la fréquence d'images
Soit fps actuel = 1/durée de chaque fréquence d'images. Après avoir obtenu la fréquence d'images en temps réel de cette manière, nous pouvons normaliser la fréquence d'images/100 en tant qu'entrée variable.

Cela fonctionne très bien. Je n'utilise que 50 populations et 5 générations, et mes résultats d'entraînement et mes résultats d'affichage sont quasiment les mêmes, ce qui veut dire que l'IA s'est adaptée à cet apport !